# -*- coding: utf-8 -*-
"""Study mate{HITS}-2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CrnwdVa5-DR6q__SPSVvZvGhiOPa7elQ
"""

# ---------------------------
# Install dependencies
# ---------------------------
!pip install faiss-cpu gradio sentence-transformers PyPDF2 pillow --quiet

import gradio as gr
import faiss
import numpy as np
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
from PIL import Image
import math

# -----------------------------
# Load embedding model
# -----------------------------
embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# -----------------------------
# Text chunking (sliding window)
# -----------------------------
def chunk_text(text, chunk_size=400, overlap=100):
    """
    chunk_size / overlap are in number of words.
    Returns list of chunks (strings).
    """
    words = text.split()
    if len(words) <= chunk_size:
        return [" ".join(words)]
    chunks = []
    start = 0
    while start < len(words):
        end = min(start + chunk_size, len(words))
        chunk = " ".join(words[start:end])
        chunks.append(chunk)
        if end == len(words):
            break
        start = end - overlap  # overlap
    return chunks

# -----------------------------
# PDF to Text
# -----------------------------
def extract_text_from_pdf(pdf_file):
    reader = PdfReader(pdf_file)
    full_text = ""
    for page in reader.pages:
        try:
            extracted = page.extract_text()
        except Exception:
            extracted = None
        if extracted:
            full_text += extracted + "\n"
    return full_text.strip()

# -----------------------------
# Build FAISS index (cosine via inner product on normalized vectors)
# -----------------------------
def build_faiss_index(text_chunks):
    # compute embeddings
    embeddings = embedder.encode(text_chunks, convert_to_numpy=True)
    # ensure float32
    embeddings = np.array(embeddings).astype("float32")
    # normalize so inner product == cosine similarity
    faiss.normalize_L2(embeddings)
    dim = embeddings.shape[1]

    # use IndexFlatIP (inner product) with normalized vectors to approximate cosine
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)
    return index

# -----------------------------
# Search FAISS (returns chunks + similarity scores)
# -----------------------------
def search_faiss(query, index, text_chunks, top_k=5):
    query = query.strip()
    if not query:
        return []

    q_embed = embedder.encode([query], convert_to_numpy=True).astype("float32")
    faiss.normalize_L2(q_embed)

    # search top_k
    D, I = index.search(q_embed, k=top_k)

    results = []
    for score, idx in zip(D[0], I[0]):
        if idx == -1:
            continue
        # score is inner product ~ cosine (because normalized)
        results.append({"score": float(score), "text": text_chunks[idx], "index": int(idx)})
    # filter duplicates and sort
    seen = set()
    unique_results = []
    for r in results:
        key = r["text"][:150]  # first 150 chars as quick dedupe heuristic
        if key in seen:
            continue
        seen.add(key)
        unique_results.append(r)
    return unique_results

# -----------------------------
# Globals
# -----------------------------
uploaded_chunks = []
faiss_index = None

# -----------------------------
# Handle PDF Upload
# -----------------------------
def upload_pdf(pdf):
    global uploaded_chunks, faiss_index

    if pdf is None:
        return "âš  Please upload a PDF file."

    text = extract_text_from_pdf(pdf)
    if not text:
        return "âŒ Error: No readable text found in the PDF."

    # chunk with sliding window
    uploaded_chunks = chunk_text(text, chunk_size=400, overlap=100)

    if len(uploaded_chunks) == 0:
        return "âŒ Error: No valid text chunks found."

    faiss_index = build_faiss_index(uploaded_chunks)
    return f"âœ… PDF uploaded & indexed successfully! ({len(uploaded_chunks)} chunks)"

# -----------------------------
# Chat with PDF (returns context snippets + simple aggregation)
# -----------------------------
def chat_with_pdf(user_msg, history):
    global faiss_index, uploaded_chunks

    if history is None:
        history = []

    user_msg_str = (user_msg or "").strip()
    if not user_msg_str:
        bot = "âš  Please type a question."
        history.append([user_msg, bot])
        return "", history

    if faiss_index is None:
        bot = "âš  Please upload a PDF first."
        history.append([user_msg, bot])
        return "", history

    # retrieve top passages
    retrieved = search_faiss(user_msg_str, faiss_index, uploaded_chunks, top_k=7)

    if not retrieved:
        bot = "âš  I couldn't find relevant content in the PDF."
        history.append([user_msg, bot])
        return "", history

    # build a concise answer: return top passages + scores
    lines = []
    for i, r in enumerate(retrieved[:5], start=1):
        score_pct = round(max(0.0, min(1.0, r["score"])) * 100, 1)  # approximate confidence %
        # truncate long passage to first 800 chars to avoid flooding
        snippet = r["text"]
        if len(snippet) > 800:
            snippet = snippet[:800].rsplit(" ", 1)[0] + "â€¦"
        lines.append(f"**Passage {i} (score {score_pct}%)**\n{snippet}\n")

    bot_reply = "ðŸ“„ **Retrieved passages (top results):**\n\n" + "\n".join(lines)

    history.append([user_msg, bot_reply])
    return "", history

# -----------------------------
# Simple Image Generator Placeholder
# -----------------------------
def gradio_generate_image(prompt):
    img = Image.new("RGB", (512, 512), color="white")
    return img

# -----------------------------
# GRADIO UI
# -----------------------------
with gr.Blocks() as app:

    gr.Markdown("# ðŸ“š PDF Chatbot + ðŸŽ¨ Image Generator â€” Improved Retrieval")

    # --- PDF CHAT TAB ---
    with gr.Tab("ðŸ“„ Chat with PDF"):
        pdf_input = gr.File(label="Upload PDF", file_types=[".pdf"])
        upload_btn = gr.Button("Process PDF")
        upload_status = gr.Textbox(label="Status", interactive=False)

        upload_btn.click(upload_pdf, inputs=pdf_input, outputs=upload_status)

        chatbot = gr.Chatbot(label="Chat History")
        user_msg = gr.Textbox(label="Ask a question about the PDF")
        ask_btn = gr.Button("Ask")

        ask_btn.click(
            chat_with_pdf,
            inputs=[user_msg, chatbot],
            outputs=[user_msg, chatbot]
        )

    # --- IMAGE GENERATOR TAB ---
    with gr.Tab("ðŸŽ¨ Image Generator"):
        img_prompt = gr.Textbox(label="Enter your image prompt")
        img_btn = gr.Button("Generate Image")
        img_output = gr.Image(label="Generated Image")

        img_btn.click(gradio_generate_image, inputs=img_prompt, outputs=img_output)

app.launch()